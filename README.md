1. <reviews_enuri.csv>
본 데이터는 가격 비교 사이트 에누리(Enuri, https://www.enuri.com)의 상품 상세 페이지에 게시된 사용자 리뷰를 웹 크롤링 방식으로 수집한 것이다. 수집 대상 URL은 https://www.enuri.com/detail.jsp?modelno=40629426이며, 공개적으로 제공되는 리뷰 정보를 기반으로 텍스트 분석 및 평점 분석을 위한 학습 및 과제 목적의 데이터셋 구축을 목표로 한다.

리뷰 데이터는 Python 기반 웹 크롤링으로 수집되었으며, Selenium WebDriver를 사용해 동적 페이지를 로딩한 뒤 리뷰 요소를 탐색하여 정보를 추출하였다. 크롤링 속도 향상을 위해 Headless 모드로 실행하고, 이미지 로딩을 차단하며(page에서 imagesEnabled=false), 페이지 로딩 전략을 eager로 설정하여 HTML 로드 이후 빠르게 파싱을 시작하도록 최적화하였다.

수집 항목은 리뷰 1건당 1행으로 구성되며, 주요 필드는 리뷰 평점(rating), 작성일(date), 리뷰 본문(content)이다. 리뷰 본문은 span.tx_sub 요소에서 추출하고, 평점은 p.tx_aval 요소에서 추출한다. 작성일은 리뷰 영역 내부의 텍스트 중 날짜 형식(예: YYYY.MM.DD)으로 판단되는 값을 탐색하여 저장한다.

본 크롤러는 목표 수집 개수를 500개로 설정하여(target_count = 500) 리뷰를 순차적으로 수집하며, 페이지네이션을 통해 다음 페이지로 이동한다. 다음 페이지 이동은 (1) 페이지 번호 버튼(button.p_num) 클릭을 우선 시도하고, 실패 시 (2) 다음(>) 버튼(button.btn.btn__next) 클릭을 시도하는 방식으로 구현되어 있다. 더 이상 이동 가능한 페이지가 없으면 수집을 종료한다.

수집된 데이터는 프로젝트 루트의 database 폴더에 CSV 파일로 저장된다. 저장 파일명은 reviews_Enuri.csv이며, UTF-8-SIG 인코딩으로 저장되어 한글 깨짐을 방지한다. 저장 로직은 현재 파일 경로 기준으로 프로젝트 루트를 계산한 뒤 database 폴더가 없으면 생성하고, pandas DataFrame으로 변환 후 CSV로 출력한다.

크롤링 실행을 위해 Python 3.9 이상 환경이 필요하며, selenium, pandas 라이브러리가 요구된다. 실행 시 WebDriver(Chrome)가 필요하며, 크롤링 스크립트 실행 후 scrape_reviews()로 데이터를 수집하고 save_to_database()를 호출하면 database/reviews_Enuri.csv 파일이 생성된다. 본 데이터는 수업 과제 및 학습 목적에 한해 사용되며, 사이트 구조 변경 또는 접근 제한 정책에 따라 정상적으로 동작하지 않을 수 있다.

2. <reviews_lotteon.csv>
본 데이터는 온라인 쇼핑몰 롯데온(LOTTE ON)의 상품 상세 페이지에 게시된 사용자 리뷰를 웹 크롤링 방식으로 수집한 것이다. 공개적으로 제공되는 리뷰 정보를 대상으로 하였으며, 텍스트 분석 및 평점 분석을 위한 학습 및 과제 목적의 데이터셋 구축을 목표로 한다.

수집된 데이터 파일은 reviews_Lotteon.csv이며, CSV 형식(UTF-8 인코딩)으로 저장되어 있다. 데이터는 리뷰 1건당 1행으로 구성되어 있으며, 총 500개의 리뷰가 포함되어 있다.

데이터는 총 3개의 컬럼으로 구성되어 있다. star 컬럼은 리뷰 평점을 나타내며 1점부터 5점까지의 정수값을 가진다. date 컬럼은 리뷰가 작성된 날짜를 의미한다. content 컬럼은 사용자가 작성한 리뷰 본문 텍스트를 나타낸다.

리뷰 데이터는 Python 기반 웹 크롤링을 통해 수집되었다. Selenium을 활용하여 동적 웹 페이지를 로딩한 후, BeautifulSoup을 이용해 HTML을 파싱하여 평점, 작성일, 리뷰 내용을 추출하였다. 이후 pandas를 사용하여 데이터를 정리하고 CSV 파일로 저장하였다.

크롤링 실행을 위해 Python 3.9 이상 환경이 필요하며, selenium, beautifulsoup4, pandas 라이브러리를 설치해야 한다. 라이브러리 설치 후 크롤링 스크립트가 위치한 디렉토리에서 python main.py -o ../../database --all 명령어를 실행하면 리뷰 데이터 수집이 진행되며, 실행 완료 후 reviews_Lotteon.csv 파일이 생성된다.

본 데이터는 수업 과제 및 학습 목적에 한해 사용되었으며, 상업적 활용은 지양해야 한다. 또한 사이트 구조 변경이나 접근 제한 정책에 따라 크롤링이 정상적으로 동작하지 않을 수 있다.

3. <reviews_emart.csv>
본 데이터는 온라인 쇼핑몰 이마트몰(EMART Mall)의 상품 상세 페이지에 게시된 사용자 리뷰를 웹 크롤링 방식으로 수집한 것이다. 공개적으로 제공되는 리뷰 정보를 대상으로 하였으며, 텍스트 분석 및 평점 분석을 위한 학습 및 과제 목적의 데이터셋 구축을 목표로 한다.

수집된 데이터 파일은 reviews_emart.csv이며, CSV 형식(UTF-8 인코딩)으로 저장되어 있다. 데이터는 리뷰 1건당 1행으로 구성되어 있으며, 총 500개의 리뷰가 포함되어 있다.

데이터는 총 3개의 컬럼으로 구성되어 있다. star 컬럼은 리뷰 평점을 나타내며 1점부터 5점까지의 정수값을 가진다. date 컬럼은 리뷰가 작성된 날짜를 의미한다. content 컬럼은 사용자가 작성한 리뷰 본문 텍스트를 나타낸다.

리뷰 데이터는 Python 기반 웹 크롤링을 통해 수집되었다. Selenium을 활용하여 동적 웹 페이지를 로딩한 후, BeautifulSoup을 이용해 HTML을 파싱하여 평점, 작성일, 리뷰 내용을 추출하였다. 이후 pandas를 사용하여 데이터를 정리하고 CSV 파일로 저장하였다.

크롤링 실행을 위해 Python 3.9 이상 환경이 필요하며, selenium, beautifulsoup4, pandas 라이브러리를 설치해야 한다. 라이브러리 설치 후 크롤링 스크립트가 위치한 디렉토리에서 python main.py -o ../../database --all 명령어를 실행하면 리뷰 데이터 수집이 진행되며, 실행 완료 후 reviews_emart.csv 파일이 생성된다.

본 데이터는 수업 과제 및 학습 목적에 한해 사용되었으며, 상업적 활용은 지양해야 한다. 또한 사이트 구조 변경이나 접근 제한 정책에 따라 크롤링이 정상적으로 동작하지 않을 수 있다.