import pandas as pd
import re
import os
from datetime import datetime

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

from review_analysis.preprocessing.base_processor import BaseDataProcessor

class LotteonProcessor(BaseDataProcessor):
    """
    ë¡¯ë°ì˜¨ ë¦¬ë·° ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ ë° FEí•˜ëŠ” í´ë˜ìŠ¤ì´ë‹¤.
    ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì•Œê¸° ìœ„í•´ ì œê±° ì‚¬ìœ ë³„ í†µê³„ë¥¼ ì¶œë ¥í•œë‹¤.
    """

    def __init__(self, input_path: str, output_dir: str) -> None:
        super().__init__(input_path, output_dir)
        self.df: pd.DataFrame = pd.DataFrame()

    def _get_season(self, month: int) -> str:
        """ì›” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„ì ˆ íŒŒìƒë³€ìˆ˜ë¥¼ ë°˜í™˜í•œë‹¤."""
        if 3 <= month <= 5:
            return 'Spring'
        elif 6 <= month <= 8:
            return 'Summer'
        elif 9 <= month <= 11:
            return 'Fall'
        else:
            return 'Winter'

    def preprocess(self) -> None:
        """
        [EDA ë° ì „ì²˜ë¦¬]
        ì œê±° ì‚¬ìœ ë³„ ë°ì´í„° ê°œìˆ˜ë¥¼ ì¶”ì í•˜ê³  ìµœì¢… ìš”ì•½ì„ ì¶œë ¥í•œë‹¤.
        """
        # 1. ë°ì´í„° ë¡œë“œ
        self.df = pd.read_csv(self.input_path)
        stats = {"ì´ˆê¸° ë°ì´í„° ê°œìˆ˜": len(self.df)}
        
        # 2. ê²°ì¸¡ì¹˜ ì œê±°(ë³„ì , ë¦¬ë·°, ë‚ ì§œ nullê°’ ì œê±°)
        pre_count = len(self.df)
        self.df.dropna(subset=['content', 'date', 'rating'], inplace=True)
        stats["ê²°ì¸¡ì¹˜(Null) ì œê±°"] = pre_count - len(self.df)
        
        # 3. ìë£Œí˜• ë³€í™˜ ë° ìœ íš¨í•˜ì§€ ì•Šì€ í˜•ì‹ ì œê±°
        pre_count = len(self.df)
        self.df['date'] = pd.to_datetime(self.df['date'], format='%Y.%m.%d', errors='coerce')
        self.df['rating'] = pd.to_numeric(self.df['rating'], errors='coerce')
        self.df.dropna(subset=['date', 'rating'], inplace=True)
        stats["í˜•ì‹ ì˜¤ë¥˜(ë‚ ì§œ/ë³„ì ) ì œê±°"] = pre_count - len(self.df)

        # 4. ê¸°ê°„ ì´ìƒì¹˜ ì²˜ë¦¬(10ë…„ ì „ ì´ìƒì˜ ê³¼ê±° ë°ì´í„°)
        pre_count = len(self.df)
        cutoff_date = pd.Timestamp.now() - pd.DateOffset(years=10)
        self.df = self.df[self.df['date'] > cutoff_date]
        stats["ê¸°ê°„ ì´ìƒì¹˜(10ë…„ ì „) ì œê±°"] = pre_count - len(self.df)
        
        # 5. ë³„ì  ì´ìƒì¹˜ ì²˜ë¦¬(1~5ì  ë²”ìœ„ ë°–)
        pre_count = len(self.df)
        self.df = self.df[(self.df['rating'] >= 1) & (self.df['rating'] <= 5)]
        stats["ë³„ì  ì´ìƒì¹˜(ë²”ìœ„ ë°–) ì œê±°"] = pre_count - len(self.df)

        # 6. í…ìŠ¤íŠ¸ ì •ì œ ë° ê¸¸ì´ ì´ìƒì¹˜ ì²˜ë¦¬(2ê¸€ì ì´í•˜)
        pre_count = len(self.df)
        self.df['cleaned_content'] = self.df['content'].apply(
            lambda x: re.sub(r'\s+', ' ', re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', str(x).replace("\n", " "))).strip()
        )
        self.df = self.df[self.df['cleaned_content'].str.len() > 2]
        stats["í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ìƒì¹˜(2ì ì´í•˜) ì œê±°"] = pre_count - len(self.df)

        # 7. ì¤‘ë³µ ë¦¬ë·° ì œê±°
        pre_count = len(self.df)
        self.df.drop_duplicates(subset=['cleaned_content'], inplace=True)
        stats["ì¤‘ë³µ ë¦¬ë·° ì œê±°"] = pre_count - len(self.df)

        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        print("\n" + "="*30)
        print(" [LotteonProcessor ì „ì²˜ë¦¬ ìš”ì•½] ")
        print("-"*30)
        for reason, count in stats.items():
            print(f" - {reason}: {count}ê°œ")
        print("-"*30)
        print(f" * ìµœì¢… ë‚¨ì€ ë°ì´í„°: {len(self.df)}ê°œ")
        print("="*30 + "\n")

    def feature_engineering(self) -> None:
        """
        [Feature Engineering ë‹¨ê³„]
        ì‹œê³„ì—´ íŒŒìƒë³€ìˆ˜ ìƒì„±, í…ìŠ¤íŠ¸ í† í°í™”, ë¦¬ë·° ê¸¸ì´(review_length) ê³„ì‚°, ê·¸ë¦¬ê³  LDA í† í”½ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•œë‹¤.

        ì´ë•Œ í† í”½ ëª¨ë¸ë§ì€ CountVectorizerë¡œ ë²¡í„°í™”(BOW) ìˆ˜í–‰í•˜ì—¬ LDA ëª¨ë¸ì„ í†µí•´ ì ì¬ëœ 3ê°€ì§€ í† í”½ì„ ì¶”ì¶œí•œë‹¤.
        ë°ì´í„° ì €ì¥ ì‹œ ë‹¨ìˆœ ìˆ«ìê°€ ì•„ë‹Œ 'í† í”½ë²ˆí˜¸(í•µì‹¬í‚¤ì›Œë“œ)' í˜•íƒœë¡œ 'topic_id' ì»¬ëŸ¼ì„ ìƒì„±í•œë‹¤.
        (ì˜ˆ: 0(ë°°ì†¡_ë¹ ë¦„_ê¸°ì‚¬ë‹˜))
        """
        if self.df.empty: return
        print(" -> Feature Engineering ìˆ˜í–‰ ì¤‘...")

        # 1. ì‹œê³„ì—´ íŒŒìƒë³€ìˆ˜
        self.df['month'] = self.df['date'].dt.month
        self.df['season'] = self.df['month'].apply(self._get_season)
        
        # 2. í† í°í™”
        self.df['tokens'] = self.df['cleaned_content'].apply(lambda x: ' '.join(re.findall(r'[ê°€-í£a-zA-Z0-9]+', x)))
        self.df['review_length'] = self.df['cleaned_content'].apply(len)

        # ---------------------------------------------------------
        #  LDA í† í”½ ëª¨ë¸ë§ (ì¸ë±ìŠ¤ + í‚¤ì›Œë“œ ì¡°í•© ì €ì¥)
        # ---------------------------------------------------------
        print(" -> ğŸ§  ë²¡í„°í™”(BOW) ë° í† í”½ ëª¨ë¸ë§(LDA) ìˆ˜í–‰ ì¤‘...")
        
        # (1) ë²¡í„°í™” ìˆ˜í–‰
        vectorizer = CountVectorizer(max_features=1000, min_df=2)
        vectorized_data = vectorizer.fit_transform(self.df['tokens'])
        
        # (2) LDA ëª¨ë¸ë§ ìˆ˜í–‰
        lda_model = LatentDirichletAllocation(n_components=3, random_state=42)
        topic_output = lda_model.fit_transform(vectorized_data)
        
        # (3) í† í”½ ì¸ë±ìŠ¤ ì¶”ì¶œ
        topic_indices = topic_output.argmax(axis=1)
        
        # (4) ì¸ë±ìŠ¤ë¥¼ 'ë²ˆí˜¸(í‚¤ì›Œë“œ)' í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        feature_names = vectorizer.get_feature_names_out()
        topic_label_dict = {}
        
        print(" -> ğŸ·ï¸ í† í”½ ë¼ë²¨ ìƒì„± ì¤‘...")
        for topic_idx, topic in enumerate(lda_model.components_):
            # ìƒìœ„ 3ê°œ ë‹¨ì–´ ì¶”ì¶œ
            top_features_ind = topic.argsort()[:-4:-1]
            top_words = [feature_names[i] for i in top_features_ind]
            
            # í˜•ì‹: ex) "0(ë°°ì†¡_ë¹ ë¦„_ê¸°ì‚¬ë‹˜)"
            keywords_str = "_".join(top_words)
            label = f"{topic_idx}({keywords_str})"
            
            topic_label_dict[topic_idx] = label
            print(f"    ğŸ“Œ Topic {topic_idx} -> {label}")
        
        # (5) ë°ì´í„°í”„ë ˆì„ì— ì ìš©
        self.df['topic_id'] = [topic_label_dict[idx] for idx in topic_indices]
        
        print(" -> âœ… 'topic_id' ì»¬ëŸ¼ ìƒì„± ì™„ë£Œ (ì˜ˆ: 0(ë°°ì†¡_ë¹ ë¦„))")

    def save_to_database(self) -> None:
        """
        ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
        """
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        save_path = os.path.join(self.output_dir, "preprocessed_reviews_Lotteon.csv")
        self.df.to_csv(save_path, index=False, encoding='utf-8-sig')
        print(f"[Success] íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")