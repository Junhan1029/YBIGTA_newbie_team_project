import pandas as pd
import re
import os
from datetime import datetime

# LDA ë° ë²¡í„°í™” ë„êµ¬
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

from review_analysis.preprocessing.base_processor import BaseDataProcessor

class EmartProcessor(BaseDataProcessor):
    """
    ì´ë§ˆíŠ¸ ë¦¬ë·° ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ ë° FEí•˜ëŠ” í´ë˜ìŠ¤ì´ë‹¤.
    ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì•Œê¸° ìœ„í•´ ì œê±° ì‚¬ìœ ë³„ í†µê³„ë¥¼ ì¶œë ¥í•œë‹¤.
    """

    def __init__(self, input_path: str, output_dir: str) -> None:
        super().__init__(input_path, output_dir)
        self.output_dir = output_dir 
        self.df: pd.DataFrame = pd.DataFrame()

    def _get_season(self, month: int) -> str:
        if 3 <= month <= 5: return 'Spring'
        elif 6 <= month <= 8: return 'Summer'
        elif 9 <= month <= 11: return 'Fall'
        else: return 'Winter'

    def preprocess(self) -> None:
        print(f"\n===== [{self.input_path}] ì „ì²˜ë¦¬ ì‹œì‘ =====")
        try:
            self.df = pd.read_csv(self.input_path)
            print(f"ğŸ“¦ ìµœì´ˆ ë°ì´í„° ë¡œë“œ: {len(self.df)}ê±´")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return

        # 1. ê²°ì¸¡ì¹˜ ì œê±°
        self.df.dropna(subset=['content', 'date', 'rating'], inplace=True)

        # 2. ë‚ ì§œ/ë³„ì  ë³€í™˜
        self.df['date'] = pd.to_datetime(self.df['date'], errors='coerce')
        self.df['rating'] = pd.to_numeric(self.df['rating'], errors='coerce')
        self.df.dropna(subset=['date', 'rating'], inplace=True)

        # 3. ê¸°ê°„ ì´ìƒì¹˜
        cutoff_date = pd.Timestamp.now() - pd.DateOffset(years=10)
        self.df = self.df[self.df['date'] > cutoff_date]

        # 4. ë³„ì  ë²”ìœ„ ì´ìƒì¹˜
        self.df = self.df[(self.df['rating'] >= 1) & (self.df['rating'] <= 5)]

        # 5. í…ìŠ¤íŠ¸ ì •ì œ
        self.df['cleaned_content'] = self.df['content'].apply(
            lambda x: re.sub(r'\s+', ' ', re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', str(x).replace("\n", " "))).strip()
        )
        self.df = self.df[self.df['cleaned_content'].str.len() > 2]

        # 6. ì¤‘ë³µ ì œê±°
        self.df.drop_duplicates(subset=['cleaned_content'], inplace=True)
        
        print(f"âœ¨ [ì „ì²˜ë¦¬ ì™„ë£Œ] ë‚¨ì€ ë°ì´í„°: {len(self.df)}ê±´")

    def feature_engineering(self) -> None:
        """
        [Feature Engineering ë‹¨ê³„]
        ì‹œê³„ì—´ íŒŒìƒë³€ìˆ˜ ìƒì„±, í…ìŠ¤íŠ¸ í† í°í™”, ë¦¬ë·° ê¸¸ì´(review_length) ê³„ì‚°, ê·¸ë¦¬ê³  LDA í† í”½ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•œë‹¤.

        ì´ë•Œ í† í”½ ëª¨ë¸ë§ì€ CountVectorizerë¡œ ë²¡í„°í™”(BOW) ìˆ˜í–‰í•˜ì—¬ LDA ëª¨ë¸ì„ í†µí•´ ì ì¬ëœ 3ê°€ì§€ í† í”½ì„ ì¶”ì¶œí•œë‹¤.
        ë°ì´í„° ì €ì¥ ì‹œ ë‹¨ìˆœ ìˆ«ìê°€ ì•„ë‹Œ 'í† í”½ë²ˆí˜¸(í•µì‹¬í‚¤ì›Œë“œ)' í˜•íƒœë¡œ 'topic_id' ì»¬ëŸ¼ì„ ìƒì„±í•œë‹¤.
        (ì˜ˆ: 0(ë°°ì†¡_ë¹ ë¦„_ê¸°ì‚¬ë‹˜))
        """
        if self.df.empty: return
        print(" -> Feature Engineering ìˆ˜í–‰ ì¤‘...")

        # 1. ì‹œê³„ì—´ íŒŒìƒë³€ìˆ˜ 
        self.df['month'] = self.df['date'].dt.month
        self.df['season'] = self.df['month'].apply(self._get_season)

        # 2. í† í°í™”
        self.df['tokens'] = self.df['cleaned_content'].apply(lambda x: ' '.join(re.findall(r'[ê°€-í£a-zA-Z0-9]+', x)))
        self.df['review_length'] = self.df['cleaned_content'].apply(len)

        # ---------------------------------------------------------
        # LDA í† í”½ ëª¨ë¸ë§
        # ---------------------------------------------------------
        print(" -> ğŸ§  ë²¡í„°í™”(BOW) ë° í† í”½ ëª¨ë¸ë§(LDA) ìˆ˜í–‰ ì¤‘...")
        
        # (1) ë²¡í„°í™”
        vectorizer = CountVectorizer(max_features=1000, min_df=2)
        vectorized_data = vectorizer.fit_transform(self.df['tokens'])
        
        # (2) LDA ëª¨ë¸ë§
        lda_model = LatentDirichletAllocation(n_components=3, random_state=42)
        topic_output = lda_model.fit_transform(vectorized_data)
        
        # (3) í† í”½ ID ë° ë¼ë²¨ ìƒì„±
        topic_indices = topic_output.argmax(axis=1)
        feature_names = vectorizer.get_feature_names_out()
        topic_label_dict = {}
        
        print(" -> ğŸ·ï¸ í† í”½ ë¼ë²¨ ìƒì„± ì¤‘...")
        for topic_idx, topic in enumerate(lda_model.components_):
            top_features_ind = topic.argsort()[:-4:-1]
            top_words = [feature_names[i] for i in top_features_ind]
            
            # ë¼ë²¨ í¬ë§·: ex) 0(ë°°ì†¡_ë¹ ë¦„_ê¸°ì‚¬ë‹˜)
            keywords_str = "_".join(top_words)
            label = f"{topic_idx}({keywords_str})"
            topic_label_dict[topic_idx] = label
            print(f"    ğŸ“Œ Topic {topic_idx} -> {label}")
        
        self.df['topic_id'] = [topic_label_dict[idx] for idx in topic_indices]
        print(" -> âœ… 'topic_id' ì»¬ëŸ¼ ìƒì„± ì™„ë£Œ")

    def save_to_database(self) -> None:
        if self.df.empty: return
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        file_name = "preprocessed_reviews_emart.csv"
        save_path = os.path.join(self.output_dir, file_name)
        self.df.to_csv(save_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")